{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1666747589433,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"},"user_tz":-210},"id":"zbyDywULOw1z","outputId":"9548bdd1-221c-4dcd-be6c-405bb2c40760"},"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Oct 26 01:26:29 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4010,"status":"ok","timestamp":1666705373974,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"},"user_tz":-210},"id":"WwwvyZTubIOm","outputId":"855e3478-2c74-4e28-da27-5544022df8a6"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"7SnT7YhEJFrG"},"source":["> # ðŸ”¶ **Pre-Settings:**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QPwDmuDmqKEN"},"outputs":[],"source":["#### --------- Settings --------\n","load_losses = False\n","load_model = False\n","load_epoch = 31\n","\n","checkpoint_path_loss = '/content/drive/Shareddrives/AI/Models/Checkpoints/MyVideoModel_Final_Residual_V7_PG/'\n","checkpoint_path_model = '/content/drive/Shareddrives/AI/Models/Checkpoints/MyVideoModel_Final_Residual_V7_PG/'\n","# ------------------------------\n","lr= 0.00002 # Learning rate # 0.00002"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6rNel-m8sMe9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666705373975,"user_tz":-210,"elapsed":22,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"}},"outputId":"da23e2b1-1dd6-4d6c-ae68-9f06acde51fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Your runtime has 13.6 gigabytes of available RAM\n","\n","Not using a high-RAM runtime\n"]}],"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('Not using a high-RAM runtime')\n","else:\n","  print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"_ebAc19vIMRb"},"source":["> # ðŸ”¶ **Download & Un-Zip Datasets:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V-xBATaBH2Dl"},"outputs":[],"source":["# !pip install --upgrade --no-cache-dir gdown"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QMv1iangz6SB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666705449819,"user_tz":-210,"elapsed":75862,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"}},"outputId":"aad4c3d9-0430-4bc6-9050-6b526290d8f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/Shareddrives/AI/Datasets/ExtractedFrames/Nature_Frames2/RawFrames_240p_6Frames_CRF13_PNG_RGB_Slow.zip\n"]}],"source":["# !unzip RawFrames_360p_6Frames_CRF0_PNG_RGB.zip -d '/content/'\n","!unzip -u '/content/drive/Shareddrives/AI/Datasets/ExtractedFrames/Nature_Frames2/RawFrames_240p_6Frames_CRF13_PNG_RGB_Slow.zip' -d '/content/'\n","# !rm -rf '/content/RawFrames_360p_6Frames_CRF17_PNG_RGB_VerySlow.zip' # RawFrames_360p_3Frames_CRF17_v2_BMP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4A27VNGvEeD"},"outputs":[],"source":["# Download Decoded Frames (CRF40):\n","# !gdown 1-EFXCAaVuA-grCf__SmMugxyoUigVYur\n","# !unzip -u '/content/drive/MyDrive/AI/Datasets/ExtractedFrames/Nature_Frames2/ResidualFrames_240p_6Frames_CRF13_40_PNG_RGB_NoNorm.zip' -d '/content/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r-o9XYVRIfEk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666705517273,"user_tz":-210,"elapsed":67482,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"}},"outputId":"820965da-949c-490d-edf4-747bca65b672"},"outputs":[{"output_type":"stream","name":"stdout","text":["Archive:  /content/drive/Shareddrives/AI/Datasets/ExtractedFrames/Nature_Frames2/CompressedFrames_240p_6Frames_CRF40_PNG_RGB.zip\n"]}],"source":["# !unzip CompressedFrames_360p_6Frames_CRF33_PNG_RGB.zip -d '/content/'\n","!unzip -u '/content/drive/Shareddrives/AI/Datasets/ExtractedFrames/Nature_Frames2/CompressedFrames_240p_6Frames_CRF40_PNG_RGB.zip' -d '/content/'\n","# !rm -rf '/content/CompressedFrames_360p_6Frames_CRF33_PNG_RGB_VerySlow.zip'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p691Z5csJs_w","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666705517795,"user_tz":-210,"elapsed":556,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"}},"outputId":"9faa6f28-80a1-4a1e-b2fc-83af8da43523"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'Video-Compression-Tools' already exists and is not an empty directory.\n","drive\timage_utils.py\tsample_data\n","Frames\t__pycache__\tVideo-Compression-Tools\n"]}],"source":["!git clone https://github.com/parhamzm/Video-Compression-Tools.git\n","\n","!cp '/content/Video-Compression-Tools/image_utils.py' './'\n","\n","from image_utils import plot_images, normalize_image\n","\n","!ls"]},{"cell_type":"markdown","metadata":{"id":"BgJcAODtJva3"},"source":["# ðŸ”¶ **Code:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3yFqptjJvD2"},"outputs":[],"source":["# %reload_ext autoreload\n","# %autoreload 2\n","%matplotlib inline\n","\n","import math\n","import time\n","import os\n","import glob\n","import json\n","import ast\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","from PIL import Image\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader, random_split\n","\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.autograd import Variable\n","\n","import torchvision\n","import torchvision.datasets as datasets\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","\n","from torchvision.datasets import ImageFolder, DatasetFolder\n","\n","from google.colab import files\n","\n","# Our libraries\n","\n","# some initial setup\n","# np.set_printoptions(precision=2)\n","use_gpu = torch.cuda.is_available()\n","# np.random.seed(1234)\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JrrDsQqGKncL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666705523580,"user_tz":-210,"elapsed":5789,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"}},"outputId":"90ac7603-0dc2-4b18-cfe2-ce069f454d5b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.9.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.4.1)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.1)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.21.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.3.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.49.1)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (1.15.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.13.0)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard) (3.9.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2022.9.24)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.2.1)\n"]}],"source":["!pip install tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3p-F7AxCJzSN"},"outputs":[],"source":["Train_decoded_DATA_DIR = '/content/Frames/CompressedFrames_CRF40/Train/'\n","Train_residual_DATA_DIR = '/content/Frames/ResidualFrames/Train/'\n","Train_raw_DATA_DIR = '/content/Frames/RawFrames/Train/'\n","\n","Test_decoded_DATA_DIR = '/content/Frames/CompressedFrames_CRF40/Test/'\n","Test_residual_DATA_DIR = '/content/Frames/ResidualFrames/Test/'\n","Test_raw_DATA_DIR = '/content/Frames/RawFrames/Test/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GWEtFfaAJ1mA"},"outputs":[],"source":["import os\n","from skimage import io\n","import pandas as pd\n","from torchvision.io import read_image\n","\n","\n","\n","class MyDataset(Dataset):\n","    def __init__(self, datasetA_dir, datasetB_dir, transform=None):\n","        self.datasetA_dir = datasetA_dir\n","        self.datasetB_dir = datasetB_dir\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        # print(\"index: \", index)\n","        # print(\"dirA: \", self.datasetA_dir)\n","        # print(\"dirB: \", self.datasetB_dir)\n","        # print(\"LenA: \", len(self.datasetA_dir))\n","        # print(\"LenB: \", len(self.datasetB_dir))\n","        digA = \"compframe\" + (\"0\" * (5 - len(str(index)))) + str(index) + \".png\"\n","        dirA = os.path.join(self.datasetA_dir, digA)\n","        digB = \"rawframe\" + (\"0\" * (5 - len(str(index)))) + str(index) + \".png\"\n","        dirB = os.path.join(self.datasetB_dir, digB)\n","        # xA = self.datasetA_dir[index]\n","        # xB = self.datasetB_dir[index]\n","        imageA = io.imread(dirA)\n","        imageB = io.imread(dirB)\n","        if self.transform:\n","            imageA = self.transform(imageA)\n","            imageB = self.transform(imageB)\n","        return imageA, imageB\n","    \n","    def __len__(self):\n","        path, dirs, filesA = next(os.walk(self.datasetA_dir))\n","        # path, dirs, filesB = next(os.walk(self.datasetB_dir))\n","        file_countA = len(filesA)\n","        # file_countB = len(filesB)\n","        # print(\"File CountA: \", file_countA)\n","        # print(\"File CountB: \", file_countB)\n","        # print(\"Len Decoded:\", len(self.datasetA_dir))\n","        # print(\"Len Raw:\", len(self.datasetB_dir))\n","        return file_countA\n","\n","\n","\n","\n","class MyDataset2(Dataset):\n","    def __init__(self, datasetA_dir, datasetB_dir, transform=None):\n","        self.datasetA_dir = datasetA_dir\n","        self.datasetB_dir = datasetB_dir\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        # print(\"index: \", index)\n","        # print(\"dirA: \", self.datasetA_dir)\n","        # print(\"dirB: \", self.datasetB_dir)\n","        # print(\"LenA: \", len(self.datasetA_dir))\n","        # print(\"LenB: \", len(self.datasetB_dir))\n","        digA = \"compframe\" + (\"0\" * (5 - len(str(index)))) + str(index) + \".png\"\n","        dirA = os.path.join(self.datasetA_dir, digA)\n","        digB = \"resframe\" + (\"0\" * (5 - len(str(index)))) + str(index) + \".png\"\n","        dirB = os.path.join(self.datasetB_dir, digB)\n","        # xA = self.datasetA_dir[index]\n","        # xB = self.datasetB_dir[index]\n","        imageA = io.imread(dirA)\n","        imageB = io.imread(dirB)\n","        if self.transform:\n","            imageA = self.transform(imageA)\n","            imageB = self.transform(imageB)\n","        return imageA, imageB\n","    \n","    def __len__(self):\n","        path, dirs, filesA = next(os.walk(self.datasetA_dir))\n","        # path, dirs, filesB = next(os.walk(self.datasetB_dir))\n","        file_countA = len(filesA)\n","        # file_countB = len(filesB)\n","        # print(\"File CountA: \", file_countA)\n","        # print(\"File CountB: \", file_countB)\n","        # print(\"Len Decoded:\", len(self.datasetA_dir))\n","        # print(\"Len Raw:\", len(self.datasetB_dir))\n","        return file_countA\n","\n","\n","transform_train = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.RandomRotation(3),\n","    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n","    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n","    transforms.RandomApply([\n","      transforms.ColorJitter(0.4, 0.4, 0.4, 0.1)], p=0.8\n","    ),\n","    transforms.RandomGrayscale(0.2),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.4914, 0.4822, 0.4465], std=[0.2023, 0.1994, 0.2010]),\n","])\n","\n","train_dataset = MyDataset(Train_decoded_DATA_DIR, Train_raw_DATA_DIR, transform=transforms.Compose([\n","                                transforms.ToTensor(),\n","                              #   torchvision.transforms.Normalize(\n","                              #     mean=[0.5, 0.5, 0.5],\n","                              #     std=[0.5, 0.5, 0.5],\n","                              # ),\n","                            ])\n",")\n","\n","test_dataset = MyDataset(Test_decoded_DATA_DIR, Test_raw_DATA_DIR, transform=transforms.Compose([\n","                                transforms.ToTensor(),\n","                              #   torchvision.transforms.Normalize(\n","                              #     mean=[0.5, 0.5, 0.5],\n","                              #     std=[0.5, 0.5, 0.5],\n","                              # ),\n","                            ])\n",")\n","\n","#   torchvision.transforms.Normalize(\n","                              #     mean=[0.485, 0.456, 0.406],\n","                              #     std=[0.229, 0.224, 0.225],\n","                              # ),"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gl1aE9UNJ3CX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666705523582,"user_tz":-210,"elapsed":9,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"}},"outputId":"9d693615-d54d-467b-f7b8-601fdc354e6b"},"outputs":[{"output_type":"stream","name":"stdout","text":["41400\n"]}],"source":["train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=True)\n","\n","# print(len(train_dataset.))\n","# print(len(train_raw_dataset.samples))\n","# print(len(test_decoded_dataset.samples))\n","# print(len(test_raw_dataset.samples))\n","# print(len(train_raw_dataset))\n","# print(len(train_decoded_dataset))\n","print(len(train_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pSG5lQX-JN8x"},"outputs":[],"source":["# my_mse = nn.MSELoss()\n","# my_mae = nn.L1Loss()\n","\n","# no_dae_loss = []\n","# for noise_batch, image_batch in tqdm(train_loader): #zip(train_decoded_loader, train_raw_loader):\n","#     loss1 = my_mae(noise_batch.to(device), image_batch.to(device))\n","#     # loss2 = my_mae(noise_batch, image_batch)\n","#     loss =  loss1\n","#     no_dae_loss.append(loss.item())\n","# print(\"Train Loss without DAE:=> {:.20f}\".format(np.mean(no_dae_loss)))\n","\n","\n","# no_dae_loss = []\n","# for noise_batch, image_batch in tqdm(test_loader): #zip(test_decoded_loader, test_raw_loader):\n","#     loss1 = my_mae(noise_batch.to(device), image_batch.to(device))\n","#     # loss2 = my_mae(noise_batch, image_batch)\n","#     loss = loss1\n","#     no_dae_loss.append(loss.item())\n","# print(\"Test Loss without DAE:=> {:.20f}\".format(np.mean(no_dae_loss)))\n","\n","# # Train Loss without DAE:=> 0.02978461904001336591\n","# # Test Loss without DAE:=> 0.03176539410450028578"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WpSokaomUdvk"},"outputs":[],"source":["batch1, batch2 = next(iter(train_loader))\n","\n","train_data = batch1\n","train_data2 = batch2\n","\n","classes = np.zeros(len(train_data)+1, dtype='int32') #0 #train_data.classes\n","\n","# plot_images(batch1, classes, classes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K5qz962yr_N1"},"outputs":[],"source":["# plot_images(batch2, classes, classes)"]},{"cell_type":"markdown","metadata":{"id":"kwsG5HBNToph"},"source":["# ðŸ”¶ **U-Net Class:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3OPtKpaKq9e4"},"outputs":[],"source":["def weights_init_normal(m):\n","    classname = m.__class__.__name__\n","    if classname.find(\"Conv\") != -1:\n","        # torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n","        # torch.nn.init.uniform_(m.weight.data, 0., 0.002)\n","        # torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n","        torch.nn.init.kaiming_normal_(m.weight.data, nonlinearity='leaky_relu', mode='fan_in')\n","    elif classname.find(\"BatchNorm2d\") != -1:\n","        # torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        # torch.nn.init.uniform_(m.weight.data, 0., 0.002)\n","        # torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n","        torch.nn.init.kaiming_normal_(m.weight.data, nonlinearity='leaky_relu', mode='fan_in')\n","        # torch.nn.init.constant_(m.bias.data, 0.0)\n","\n","\n","def initialize_weights(m):\n","  if isinstance(m, nn.Conv2d):\n","      nn.init.kaiming_uniform_(m.weight.data, nonlinearity='leaky_relu')\n","      # torch.nn.init.xavier_uniform_(m.weight.data, gain=1.0)\n","      # torch.nn.init.uniform_(m.weight.data, 0., 0.02)\n","      if m.bias is not None:\n","          nn.init.constant_(m.bias.data, 0)\n","  elif isinstance(m, nn.BatchNorm2d):\n","      nn.init.constant_(m.weight.data, 1)\n","      nn.init.constant_(m.bias.data, 0)\n","  elif isinstance(m, nn.Linear):\n","      nn.init.kaiming_uniform_(m.weight.data, nonlinearity='leaky_relu')\n","      # torch.nn.init.xavier_uniform_(m.weight.data, gain=1.0)\n","      # torch.nn.init.uniform_(m.weight.data, 0., 0.02)\n","      nn.init.constant_(m.bias.data, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"da_Ohuso_r_T"},"outputs":[],"source":["#########################################\n","#           U-NET -             #\n","#########################################\n","def crop(image, new_shape):\n","    '''\n","    Function for cropping an image tensor: Given an image tensor and the new shape,\n","    crops to the center pixels (assumes that the input's size and the new size are\n","    even numbers).\n","    Parameters:\n","        image: image tensor of shape (batch size, channels, height, width)\n","        new_shape: a torch.Size object with the shape you want x to have\n","    '''\n","    # There are many ways to implement this crop function, but it's what allows\n","    # the skip connection to function as intended with two differently sized images!\n","    #### START CODE HERE ####\n","    middle_height = image.shape[2] // 2\n","    middle_width = image.shape[3] // 2\n","    starting_height = middle_height - round(new_shape[2] / 2)\n","    final_height = starting_height + new_shape[2]\n","    starting_width = middle_width - round(new_shape[3] / 2)\n","    final_width = starting_width + new_shape[3]\n","    cropped_image = image[:, :, starting_height:final_height, starting_width:final_width]\n","    return cropped_image\n","\n","class ResidualBlock(nn.Module):\n","    '''\n","    ResidualBlock Class:\n","    Performs two convolutions and an instance normalization, the input is added\n","    to this output to form the residual block output.\n","    Values:\n","        input_channels: the number of channels to expect from a given input\n","    '''\n","    def conv_block(self, in_features, kernal_size, padding, use_bn=True, activation='relu'):\n","        activations = nn.ModuleDict([\n","                ['lrelu', nn.LeakyReLU(0.2, inplace=True)],\n","                ['relu', nn.ReLU(inplace=True)],\n","                ['celu', torch.nn.CELU(alpha=1.0, inplace=True)],\n","                ['rrelu', nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=True)],\n","        ])\n","        if use_bn:\n","            layers = [\n","              torch.nn.Conv2d(in_features, in_features, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              nn.InstanceNorm2d(in_features),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features, in_features, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              nn.InstanceNorm2d(in_features),\n","            ]\n","        else:\n","            layers = [\n","              torch.nn.Conv2d(in_features, in_features, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features, in_features, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","            ]\n","        block = torch.nn.Sequential(*layers)\n","        return block\n","\n","    def __init__(self, input_channels, k=9, p=4, use_bn=True):\n","        super(ResidualBlock, self).__init__()\n","        self.residual_layer1 = self.conv_block(in_features=input_channels, kernal_size=k, padding=p, use_bn=use_bn)\n","\n","    def forward(self, x):\n","        '''\n","        Function for completing a forward pass of ResidualBlock: \n","        Given an image tensor, completes a residual block and returns the transformed tensor.\n","        Parameters:\n","            x: image tensor of shape (batch size, channels, height, width)\n","        '''\n","        original_x = x.clone()\n","        x = self.residual_layer1(x)\n","        return original_x + x\n","\n","\n","class ResidualingBlock(nn.Module):\n","    def res_block(self, in_features, kernal_size, padding, use_bn=True, activation='relu'):\n","        activations = nn.ModuleDict([\n","                ['lrelu', nn.LeakyReLU(0.2, inplace=True)],\n","                ['relu', nn.ReLU(inplace=True)],\n","                ['celu', torch.nn.CELU(alpha=1.0, inplace=True)],\n","                ['rrelu', nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=True)],\n","        ])\n","        if use_bn:\n","            layers = [\n","            #   torch.nn.Conv2d(in_features, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='zeros'),\n","            #   nn.InstanceNorm2d(in_features * 2),\n","            #   activations[activation],\n","              ResidualBlock(input_channels=in_features, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features, k=kernal_size, p=padding, use_bn=use_bn)\n","            ]\n","\n","        block = torch.nn.Sequential(*layers)\n","        return block\n","\n","\n","    def __init__(self, input_channels, k=9, p=4, use_bn=True):\n","        super(ResidualingBlock, self).__init__()\n","        self.residual_block1 = self.res_block(in_features=input_channels, kernal_size=k, padding=p, use_bn=use_bn)\n","\n","    def forward(self, x):\n","        '''\n","        Function for completing a forward pass of ResidualBlock: \n","        Given an image tensor, completes a residual block and returns the transformed tensor.\n","        Parameters:\n","            x: image tensor of shape (batch size, channels, height, width)\n","        '''\n","        x = self.residual_block1(x)\n","        return x\n","    \n","\n","class ContractingBlockBase(nn.Module):\n","    '''\n","    ContractingBlock Class\n","    Performs two convolutions followed by a max pool operation.\n","    Values:\n","        input_channels: the number of channels to expect from a given input\n","    '''\n","    def conv_block(self, in_features, kernal_size, padding, use_bn=True, max_pool=False, activation='lrelu'):\n","        activations = nn.ModuleDict([\n","                ['lrelu', nn.LeakyReLU(0.2, inplace=True)],\n","                ['relu', nn.ReLU(inplace=True)],\n","                ['celu', torch.nn.CELU(alpha=1.0, inplace=True)],\n","                ['rrelu', nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=True)],\n","        ])\n","        if use_bn:\n","            layers = [\n","              torch.nn.Conv2d(in_features, in_features, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              nn.InstanceNorm2d(in_features),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features, in_features, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              nn.InstanceNorm2d(in_features * 2),\n","              activations[activation],\n","              ResidualBlock(input_channels=in_features, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features, k=kernal_size, p=padding, use_bn=use_bn),\n","            ]\n","        else:\n","            layers = [\n","              torch.nn.Conv2d(in_features, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features * 2, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features * 2, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features * 2, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features * 2, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","            ]\n","        if max_pool:\n","            layers.append(\n","                nn.Conv2d(in_features * 2, in_features * 2, kernel_size=2, stride=2, padding=0, padding_mode='reflect') # k+1, p\n","            )\n","        block = torch.nn.Sequential(*layers)\n","        return block\n","\n","    def __init__(self, input_channels, use_dropout=False, use_bn=True, use_max_pool=True, k=7, p=3):\n","        super(ContractingBlockBase, self).__init__()\n","        # You want to double the number of channels in the first convolution\n","        # and keep the same number of channels in the second.\n","        #### START CODE HERE ####\n","        self.contracting_layer1 = self.conv_block(in_features=input_channels, kernal_size=k, padding=p, use_bn=use_bn, max_pool=use_max_pool)\n","        # if use_dropout:\n","        #     self.dropout = nn.Dropout(p=0.3, inplace=True)\n","        #### END CODE HERE ####\n","\n","    def forward(self, x):\n","        '''\n","        Function for completing a forward pass of ContractingBlock: \n","        Given an image tensor, completes a contracting block and returns the transformed tensor.\n","        Parameters:\n","            x: image tensor of shape (batch size, channels, height, width)\n","        '''\n","        x = self.contracting_layer1(x)\n","        return x\n","\n","\n","# CLASS: ContractingBlock\n","class ContractingBlock(nn.Module):\n","    '''\n","    ContractingBlock Class\n","    Performs two convolutions followed by a max pool operation.\n","    Values:\n","        input_channels: the number of channels to expect from a given input\n","    '''\n","    def conv_block(self, in_features, kernal_size, padding, use_bn=True, max_pool=False, activation='lrelu'):\n","        activations = nn.ModuleDict([\n","                ['lrelu', nn.LeakyReLU(0.2, inplace=True)],\n","                ['relu', nn.ReLU(inplace=True)],\n","                ['celu', torch.nn.CELU(alpha=1.0, inplace=True)],\n","                ['rrelu', nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=True)],\n","        ])\n","        if use_bn:\n","            layers = [\n","              torch.nn.Conv2d(in_features, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              nn.InstanceNorm2d(in_features * 2),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features * 2, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              nn.InstanceNorm2d(in_features * 2),\n","              activations[activation],\n","              ResidualBlock(input_channels=in_features * 2, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features * 2, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features * 2, k=kernal_size, p=padding, use_bn=use_bn),\n","            ]\n","        else:\n","            layers = [\n","              torch.nn.Conv2d(in_features, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features * 2, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features * 2, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features * 2, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features * 2, in_features * 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","            ]\n","        if max_pool:\n","            layers.append(\n","                nn.Conv2d(in_features * 2, in_features * 2, kernel_size=2, stride=2, padding=0, padding_mode='reflect') # k+1, p\n","            )\n","        block = torch.nn.Sequential(*layers)\n","        return block\n","\n","    def __init__(self, input_channels, use_dropout=False, use_bn=True, use_max_pool=True, k=7, p=3):\n","        super(ContractingBlock, self).__init__()\n","        # You want to double the number of channels in the first convolution\n","        # and keep the same number of channels in the second.\n","        #### START CODE HERE ####\n","        self.contracting_layer1 = self.conv_block(in_features=input_channels, kernal_size=k, padding=p, use_bn=use_bn, max_pool=use_max_pool)\n","        # if use_dropout:\n","        #     self.dropout = nn.Dropout(p=0.3, inplace=True)\n","        #### END CODE HERE ####\n","\n","    def forward(self, x):\n","        '''\n","        Function for completing a forward pass of ContractingBlock: \n","        Given an image tensor, completes a contracting block and returns the transformed tensor.\n","        Parameters:\n","            x: image tensor of shape (batch size, channels, height, width)\n","        '''\n","        x = self.contracting_layer1(x)\n","        return x\n","\n","\n","\n","# CLASS: ExpandingBlock\n","class ExpandingBlock(nn.Module):\n","    '''\n","    ExpandingBlock Class\n","    Performs an upsampling, a convolution, a concatenation of its two inputs,\n","    followed by two more convolutions.\n","    Values:\n","        input_channels: the number of channels to expect from a given input\n","    '''\n","    def conv_block1(self, in_features, kernal_size, padding, upsample=False):\n","        activations = nn.ModuleDict([\n","                ['lrelu', nn.LeakyReLU(0.2, inplace=True)],\n","                ['relu', nn.ReLU(inplace=True)],\n","                ['celu', torch.nn.CELU(alpha=1.0, inplace=True)],\n","                ['rrelu', nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=True)],\n","        ])\n","        if upsample:\n","            layers_part1 = [\n","                nn.ConvTranspose2d(in_features, in_features // 2, kernel_size=2, stride=2, padding=0) # k+1, p\n","            ]\n","        else:\n","            layers_part1 = [\n","                nn.Conv2d(in_features, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect')\n","            ]\n","            \n","        block1 = torch.nn.Sequential(*layers_part1)\n","        return block1\n","\n","    def conv_block2(self, in_features, kernal_size, padding, use_bn=False, activation='celu'):\n","        activations = nn.ModuleDict([\n","                ['lrelu', nn.LeakyReLU(0.2, inplace=True)],\n","                ['relu', nn.ReLU(inplace=True)],\n","                ['celu', torch.nn.CELU(alpha=1.0, inplace=True)],\n","                ['rrelu', nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=True)],\n","        ])\n","        if use_bn:\n","            layers = [\n","              torch.nn.Conv2d(in_features, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              nn.InstanceNorm2d(in_features // 2),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features // 2, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              nn.InstanceNorm2d(in_features // 2),\n","              activations[activation],\n","\n","              ResidualBlock(input_channels=in_features // 2, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features // 2, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features // 2, k=kernal_size, p=padding, use_bn=use_bn),\n","            ]\n","        else:\n","            layers = [\n","              torch.nn.Conv2d(in_features, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features // 2, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features // 2, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features // 2, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features // 2, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","            ]\n","        \n","        block2 = torch.nn.Sequential(*layers)\n","        return block2\n","\n","    def __init__(self, input_channels, use_dropout=False, use_bn=False, use_trans_conv=True, k=7, p=3):\n","        super(ExpandingBlock, self).__init__()\n","        # \"Every step in the expanding path consists of an upsampling of the feature map\"\n","        # self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        self.expanding_layer1 = self.conv_block1(in_features=input_channels, kernal_size=k, padding=p, upsample=use_trans_conv)\n","        # \"followed by a 2x2 convolution that halves the number of feature channels\"\n","        # \"a concatenation with the correspondingly cropped feature map from the contracting path\"\n","        # \"and two 3x3 convolutions\"\n","        self.expanding_layer2 = self.conv_block2(in_features=input_channels, kernal_size=k, padding=p, use_bn=use_bn)\n","        #### START CODE HERE ####\n","        # if use_dropout:\n","        #     self.dropout = nn.Dropout()\n","        # self.use_dropout = use_dropout\n","        #### END CODE HERE ####\n","        # \"each followed by a ReLU\"\n"," \n","    def forward(self, x, skip_con_x):\n","        '''\n","        Function for completing a forward pass of ExpandingBlock: \n","        Given an image tensor, completes an expanding block and returns the transformed tensor.\n","        Parameters:\n","            x: image tensor of shape (batch size, channels, height, width)\n","            skip_con_x: the image tensor from the contracting path (from the opposing block of x)\n","                    for the skip connection\n","        '''\n","        x = self.expanding_layer1(x)\n","        # print(\"Shape before cat:==> \", x.shape)\n","        # skip_con_x = crop(skip_con_x, x.shape)\n","        x = torch.cat([x, skip_con_x], axis=1)\n","        # print(\"Shape after cat:==> \", x.shape)\n","        x = self.expanding_layer2(x)\n","        return x\n","\n","\n","class ExpandingBlockBase(nn.Module):\n","    '''\n","    ExpandingBlock Class\n","    Performs an upsampling, a convolution, a concatenation of its two inputs,\n","    followed by two more convolutions.\n","    Values:\n","        input_channels: the number of channels to expect from a given input\n","    '''\n","    def conv_block1(self, in_features, kernal_size, padding, upsample=False):\n","        activations = nn.ModuleDict([\n","                ['lrelu', nn.LeakyReLU(0.2, inplace=True)],\n","                ['relu', nn.ReLU(inplace=True)],\n","                ['celu', torch.nn.CELU(alpha=1.0, inplace=True)],\n","                ['rrelu', nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=True)],\n","        ])\n","        if upsample:\n","            layers_part1 = [\n","                nn.ConvTranspose2d(in_features, in_features, kernel_size=2, stride=2, padding=0) # k+1, p\n","            ]\n","        else:\n","            layers_part1 = [\n","                nn.Conv2d(in_features, in_features, kernel_size=kernal_size, padding=padding, padding_mode='reflect')\n","            ]\n","\n","        block1 = torch.nn.Sequential(*layers_part1)\n","        return block1\n","\n","    def conv_block2(self, in_features, kernal_size, padding, use_bn=False, activation='celu'):\n","        activations = nn.ModuleDict([\n","                ['lrelu', nn.LeakyReLU(0.2, inplace=True)],\n","                ['relu', nn.ReLU(inplace=True)],\n","                ['celu', torch.nn.CELU(alpha=1.0, inplace=True)],\n","                ['rrelu', nn.RReLU(lower=0.125, upper=0.3333333333333333, inplace=True)],\n","        ])\n","        if use_bn:\n","            layers = [\n","              torch.nn.Conv2d(in_features * 2, in_features, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              nn.InstanceNorm2d(in_features),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features, in_features, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              nn.InstanceNorm2d(in_features),\n","              activations[activation],\n","\n","              ResidualBlock(input_channels=in_features, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features, k=kernal_size, p=padding, use_bn=use_bn),\n","              ResidualBlock(input_channels=in_features, k=kernal_size, p=padding, use_bn=use_bn),\n","            ]\n","        else:\n","            layers = [\n","              torch.nn.Conv2d(in_features, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features // 2, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features // 2, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features // 2, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","              torch.nn.Conv2d(in_features // 2, in_features // 2, kernel_size=kernal_size, padding=padding, padding_mode='reflect'),\n","              activations[activation],\n","            ]\n","        \n","        block2 = torch.nn.Sequential(*layers)\n","        return block2\n","\n","    def __init__(self, input_channels, use_dropout=False, use_bn=False, use_trans_conv=True, k=7, p=3):\n","        super(ExpandingBlockBase, self).__init__()\n","        # \"Every step in the expanding path consists of an upsampling of the feature map\"\n","        # self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","        self.expanding_layer1 = self.conv_block1(in_features=input_channels, kernal_size=k, padding=p, upsample=use_trans_conv)\n","        # \"followed by a 2x2 convolution that halves the number of feature channels\"\n","        # \"a concatenation with the correspondingly cropped feature map from the contracting path\"\n","        # \"and two 3x3 convolutions\"\n","        self.expanding_layer2 = self.conv_block2(in_features=input_channels, kernal_size=k, padding=p, use_bn=use_bn)\n","        #### START CODE HERE ####\n","        # if use_dropout:\n","        #     self.dropout = nn.Dropout()\n","        # self.use_dropout = use_dropout\n","        #### END CODE HERE ####\n","        # \"each followed by a ReLU\"\n"," \n","    def forward(self, x, skip_con_x):\n","        '''\n","        Function for completing a forward pass of ExpandingBlock: \n","        Given an image tensor, completes an expanding block and returns the transformed tensor.\n","        Parameters:\n","            x: image tensor of shape (batch size, channels, height, width)\n","            skip_con_x: the image tensor from the contracting path (from the opposing block of x)\n","                    for the skip connection\n","        '''\n","        x = self.expanding_layer1(x)\n","        # print(\"Shape before cat:==> \", x.shape)\n","        # skip_con_x = crop(skip_con_x, x.shape)\n","        x = torch.cat([x, skip_con_x], axis=1)\n","        # print(\"Shape after cat:==> \", x.shape)\n","        x = self.expanding_layer2(x)\n","        return x\n","\n","\n","\n","# CLASS: FeatureMapBlock\n","class FeatureMapBlock(nn.Module):\n","    '''\n","    FeatureMapBlock Class\n","    The final layer of a Generator - \n","    maps each the output to the desired number of output channels\n","    Values:\n","        input_channels: the number of channels to expect from a given input\n","        output_channels: the number of channels to expect for a given output\n","    '''\n","    def __init__(self, input_channels, output_channels, k=13, p=6):\n","        super(FeatureMapBlock, self).__init__()\n","        self.conv0 = nn.Conv2d(input_channels, output_channels, kernel_size=k, padding=p, padding_mode='reflect')\n","        # self.conv1 = nn.Conv2d(output_channels, output_channels, kernel_size=k, padding=p, padding_mode='reflect')\n","        # self.conv2 = nn.Conv2d(output_channels, output_channels, kernel_size=k, padding=p, padding_mode='reflect')\n","\n","    def forward(self, x):\n","        '''\n","        Function for completing a forward pass of FeatureMapBlock: \n","        Given an image tensor, returns it mapped to the desired number of channels.\n","        Parameters:\n","            x: image tensor of shape (batch size, channels, height, width)\n","        '''\n","        x = self.conv0(x)\n","        # x = self.conv1(x)\n","        # x = self.conv2(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c64kUWGGToDc"},"outputs":[],"source":["# GRADED CLASS: UNet\n","class UNet(nn.Module):\n","    '''\n","    UNet Class\n","    A series of 4 contracting blocks followed by 4 expanding blocks to \n","    transform an input image into the corresponding paired image, with an upfeature\n","    layer at the start and a downfeature layer at the end\n","    Values:\n","        input_channels: the number of channels to expect from a given input\n","        output_channels: the number of channels to expect for a given output\n","    '''\n","    def __init__(self, input_channels=3, output_channels=3, hidden_channels=4):\n","        super(UNet, self).__init__()\n","        # \"Every step in the expanding path consists of an upsampling of the feature map\"\n","        self.upfeature = FeatureMapBlock(input_channels, hidden_channels)\n","        self.contract1 = ContractingBlock(hidden_channels, use_dropout=False, use_bn=True, use_max_pool=False)\n","        self.contract2 = ContractingBlock(hidden_channels * 2, use_dropout=False, use_bn=True, use_max_pool=False)\n","        self.contract3 = ContractingBlock(hidden_channels * 4, use_dropout=False, use_bn=True, use_max_pool=True)\n","        self.contract4 = ContractingBlock(hidden_channels * 8, use_dropout=False, use_bn=True, use_max_pool=False)\n","        self.contract5 = ContractingBlock(hidden_channels * 16, use_dropout=False, use_bn=True, use_max_pool=True)\n","        self.contract6 = ContractingBlock(hidden_channels * 32, use_dropout=False, use_bn=True, use_max_pool=False)\n","        self.contract7 = ContractingBlock(hidden_channels * 64, use_dropout=False, use_bn=True, use_max_pool=True)\n","        # self.contract8 = ContractingBlock(hidden_channels * 64, use_dropout=False, use_bn=True, use_max_pool=False)\n","        res_mult = 128\n","        self.res0 = ResidualBlock(hidden_channels * res_mult, k=9, p=4, use_bn=True)\n","        self.res1 = ResidualBlock(hidden_channels * res_mult, k=9, p=4, use_bn=True)\n","        self.res2 = ResidualBlock(hidden_channels * res_mult, k=9, p=4, use_bn=True)\n","        self.res3 = ResidualBlock(hidden_channels * res_mult, k=9, p=4, use_bn=True)\n","        self.res4 = ResidualBlock(hidden_channels * res_mult, k=9, p=4, use_bn=True)\n","        self.res5 = ResidualBlock(hidden_channels * res_mult, k=9, p=4, use_bn=True)\n","        self.res6 = ResidualBlock(hidden_channels * res_mult, k=9, p=4, use_bn=True)\n","        self.res7 = ResidualBlock(hidden_channels * res_mult, k=9, p=4, use_bn=True)\n","        self.res8 = ResidualBlock(hidden_channels * res_mult, k=9, p=4, use_bn=True)\n","        # self.expand0 = ExpandingBlock(hidden_channels * 128, use_dropout=False, use_bn=True, use_trans_conv=False)\n","        self.expand1 = ExpandingBlock(hidden_channels * 128, use_dropout=False, use_bn=True, use_trans_conv=True)\n","        self.expand2 = ExpandingBlock(hidden_channels * 64, use_dropout=False, use_bn=True, use_trans_conv=False)\n","        self.expand3 = ExpandingBlock(hidden_channels * 32, use_dropout=False, use_bn=True, use_trans_conv=True)\n","        self.expand4 = ExpandingBlock(hidden_channels * 16, use_dropout=False, use_bn=True, use_trans_conv=False)\n","        self.expand5 = ExpandingBlock(hidden_channels * 8, use_dropout=False, use_bn=True, use_trans_conv=True)\n","        self.expand6 = ExpandingBlock(hidden_channels * 4, use_dropout=False, use_bn=True, use_trans_conv=False)\n","        self.expand7 = ExpandingBlock(hidden_channels * 2, use_dropout=False, use_bn=True, use_trans_conv=False)\n","        self.downfeature = FeatureMapBlock(hidden_channels, output_channels)\n","        self.res_end1 = ResidualBlock(output_channels, k=13, p=6, use_bn=True)\n","        self.res_end2 = ResidualBlock(output_channels, k=13, p=6, use_bn=True)\n","        self.res_end3 = ResidualBlock(output_channels, k=13, p=6, use_bn=True)\n","        self.res_end4 = ResidualBlock(output_channels, k=13, p=6, use_bn=True)\n","        self.res_end5 = ResidualBlock(output_channels, k=13, p=6, use_bn=True)\n","        # self.tanh = torch.nn.Tanh()\n","        self.soft_sign = torch.nn.Softsign()\n","        # self.sigmoid = torch.nn.Sigmoid()\n","\n","    def forward(self, x):\n","        '''\n","        Function for completing a forward pass of UNet: \n","        Given an image tensor, passes it through U-Net and returns the output.\n","        Parameters:\n","            x: image tensor of shape (batch size, channels, height, width)\n","        '''\n","        # Keep in mind that the expand function takes two inputs, \n","        # both with the same number of channels. \n","        #### START CODE HERE ####\n","        x0 = self.upfeature(x)\n","        x1 = self.contract1(x0)\n","        x2 = self.contract2(x1)\n","        x3 = self.contract3(x2)\n","        x4 = self.contract4(x3)\n","        x5 = self.contract5(x4)\n","        x6 = self.contract6(x5)\n","        x7 = self.contract7(x6)\n","        # x8 = self.contract8(x7)\n","        y3 = self.res0(x7)\n","        y4 = self.res1(y3)\n","        y5 = self.res2(y4)\n","        y6 = self.res3(y5)\n","        y7 = self.res4(y6)\n","        y8 = self.res5(y7)\n","        y9 = self.res6(y8)\n","        y10 = self.res7(y9)\n","        y11 = self.res8(y10)\n","        # z1 = self.expand0(y11, x7)\n","        z2 = self.expand1(y11, x6)\n","        z3 = self.expand2(z2, x5)\n","        z4 = self.expand3(z3, x4)\n","        z5 = self.expand4(z4, x3)\n","        z6 = self.expand5(z5, x2)\n","        z7 = self.expand6(z6, x1)\n","        z8 = self.expand7(z7, x0)\n","        xn = self.downfeature(z8)\n","        xn = self.res_end1(xn)\n","        xn = self.res_end2(xn)\n","        xn = self.res_end3(xn)\n","        xn = self.res_end4(xn)\n","        xn = self.res_end5(xn)\n","        # xn = self.sigmoid(xn)\n","        xn = self.soft_sign(xn)\n","        #### END CODE HERE ####\n","        return xn"]},{"cell_type":"code","source":["class AdaIN(nn.Module):\n","    '''\n","    AdaIN Class\n","    Values:\n","        channels: the number of channels the image has, a scalar\n","        w_dim: the dimension of the intermediate noise vector, a scalar\n","    '''\n","\n","    def __init__(self, channels, w_dim):\n","        super().__init__()\n","\n","        # Normalize the input per-dimension\n","        self.instance_norm = nn.InstanceNorm2d(channels)\n","\n","        # You want to map w to a set of style weights per channel.\n","        # Replace the Nones with the correct dimensions - keep in mind that \n","        # both linear maps transform a w vector into style weights \n","        # corresponding to the number of image channels.\n","        #### START CODE HERE ####\n","        self.style_scale_transform = nn.Linear(w_dim, channels)\n","        self.style_shift_transform = nn.Linear(w_dim, channels)\n","        #### END CODE HERE ####\n","\n","    def forward(self, image, w):\n","        '''\n","        Function for completing a forward pass of AdaIN: Given an image and intermediate noise vector w, \n","        returns the normalized image that has been scaled and shifted by the style.\n","        Parameters:\n","            image: the feature map of shape (n_samples, channels, width, height)\n","            w: the intermediate noise vector\n","        '''\n","        normalized_image = self.instance_norm(image)\n","        style_scale = self.style_scale_transform(w)[:, :, None, None]\n","        style_shift = self.style_shift_transform(w)[:, :, None, None]\n","        \n","        # Calculate the transformed image\n","        #### START CODE HERE ####\n","        transformed_image = style_scale * normalized_image + style_shift\n","        #### END CODE HERE ####\n","        return transformed_image\n","        \n","\n","class MicroStyleGANGeneratorBlock(nn.Module):\n","    '''\n","    Micro StyleGAN Generator Block Class\n","    Values:\n","        in_chan: the number of channels in the input, a scalar\n","        out_chan: the number of channels wanted in the output, a scalar\n","        w_dim: the dimension of the intermediate noise vector, a scalar\n","        kernel_size: the size of the convolving kernel\n","        starting_size: the size of the starting image\n","    '''\n","\n","    def __init__(self, in_chan, out_chan, w_dim, kernel_size, starting_size, use_upsample=True):\n","        super().__init__()\n","        self.use_upsample = use_upsample\n","        # Replace the Nones in order to:\n","        # 1. Upsample to the starting_size, bilinearly (https://pytorch.org/docs/master/generated/torch.nn.Upsample.html)\n","        # 2. Create a kernel_size convolution which takes in \n","        #    an image with in_chan and outputs one with out_chan (https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n","        # 3. Create an object to inject noise\n","        # 4. Create an AdaIN object\n","        # 5. Create a LeakyReLU activation with slope 0.2\n","        \n","        #### START CODE HERE ####\n","        if self.use_upsample:\n","            self.upsample = nn.Upsample((starting_size), mode='bilinear')\n","        self.conv = nn.Conv2d(in_chan, out_chan, kernel_size, padding=1) # Padding is used to maintain the image size\n","        self.inject_noise = InjectNoise(out_chan)\n","        self.adain = AdaIN(out_chan, w_dim)\n","        self.activation = nn.LeakyReLU(0.2)\n","        #### END CODE HERE ####\n","\n","    def forward(self, x, w):\n","        '''\n","        Function for completing a forward pass of MicroStyleGANGeneratorBlock: Given an x and w, \n","        computes a StyleGAN generator block.\n","        Parameters:\n","            x: the input into the generator, feature map of shape (n_samples, channels, width, height)\n","            w: the intermediate noise vector\n","        '''\n","        if self.use_upsample:\n","            x = self.upsample(x)\n","        x = self.conv(x)\n","        x = self.inject_noise(x)\n","        x = self.activation(x)\n","        x = self.adain(x, w)\n","        return x\n","\n","\n","class ProgressiveGrowingNUClassNet(nn.Module):\n","    '''\n","    '''\n","\n","    def __init__(self, z_dim, map_hidden_dim, w_dim, in_chan, out_chan, kernel_size, hidden_chan):\n","        super().__init__()\n","        self.map = MappingLayers(z_dim, map_hidden_dim, w_dim)\n","        # Typically this constant is initiated to all ones, but you will initiate to a\n","        # Gaussian to better visualize the network's effect\n","        self.starting_constant = nn.Parameter(torch.randn(1, in_chan, 4, 4))\n","        self.block0 = MicroStyleGANGeneratorBlock(in_chan, hidden_chan, w_dim, kernel_size, 4, use_upsample=False)\n","        self.block1 = MicroStyleGANGeneratorBlock(hidden_chan, hidden_chan, w_dim, kernel_size, 8)\n","        self.block2 = MicroStyleGANGeneratorBlock(hidden_chan, hidden_chan, w_dim, kernel_size, 16)\n","        # You need to have a way of mapping from the output noise to an image, \n","        # so you learn a 1x1 convolution to transform the e.g. 512 channels into 3 channels\n","        # (Note that this is simplified, with clipping used in the real StyleGAN)\n","        self.block1_to_image = nn.Conv2d(hidden_chan, out_chan, kernel_size=1)\n","        self.block2_to_image = nn.Conv2d(hidden_chan, out_chan, kernel_size=1)\n","        self.alpha = 0.2\n","\n","    def upsample_to_match_size(self, smaller_image, bigger_image):\n","        '''\n","        Function for upsampling an image to the size of another: Given a two images (smaller and bigger), \n","        upsamples the first to have the same dimensions as the second.\n","        Parameters:\n","            smaller_image: the smaller image to upsample\n","            bigger_image: the bigger image whose dimensions will be upsampled to\n","        '''\n","        return F.interpolate(smaller_image, size=bigger_image.shape[-2:], mode='bilinear')\n","\n","    def forward(self, noise, return_intermediate=False):\n","        '''\n","        Function for completing a forward pass of MicroStyleGANGenerator: Given noise, \n","        computes a StyleGAN iteration.\n","        Parameters:\n","            noise: a noise tensor with dimensions (n_samples, z_dim)\n","            return_intermediate: a boolean, true to return the images as well (for testing) and false otherwise\n","        '''\n","        x = self.starting_constant\n","        w = self.map(noise)\n","        x = self.block0(x, w)\n","        x_small = self.block1(x, w) # First generator run output\n","        x_small_image = self.block1_to_image(x_small)\n","        x_big = self.block2(x_small, w) # Second generator run output \n","        x_big_image = self.block2_to_image(x_big)\n","        x_small_upsample = self.upsample_to_match_size(x_small_image, x_big_image) # Upsample first generator run output to be same size as second generator run output \n","        # Interpolate between the upsampled image and the image from the generator using alpha\n","        \n","        #### START CODE HERE ####\n","        interpolation = self.alpha * (x_big_image) + (1-self.alpha) * (x_small_upsample)\n","        #### END CODE HERE #### \n","        \n","        if return_intermediate:\n","            return interpolation, x_small_upsample, x_big_image\n","        return interpolation"],"metadata":{"id":"oSlShVFNh1uJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r3qmP0qBMzjo"},"source":["# ðŸ”¶ **Initialize Model:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MPWOxuAPKmes"},"outputs":[],"source":["\n","### Set the random seed for reproducible results\n","# torch.manual_seed(0)\n","\n","### Initialize the two networks\n","# del u_net\n","\n","u_net = UNet(input_channels=3, output_channels=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5775,"status":"ok","timestamp":1666712825418,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"},"user_tz":-210},"id":"1zi73ibQy5P8","outputId":"5121497a-f356-48d4-8344-89b5612f9b21"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["UNet(\n","  (upfeature): FeatureMapBlock(\n","    (conv0): Conv2d(3, 4, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","  )\n","  (contract1): ContractingBlock(\n","    (contracting_layer1): Sequential(\n","      (0): Conv2d(4, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (3): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","    )\n","  )\n","  (contract2): ContractingBlock(\n","    (contracting_layer1): Sequential(\n","      (0): Conv2d(8, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (3): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","    )\n","  )\n","  (contract3): ContractingBlock(\n","    (contracting_layer1): Sequential(\n","      (0): Conv2d(16, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (3): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (9): Conv2d(32, 32, kernel_size=(2, 2), stride=(2, 2), padding_mode=reflect)\n","    )\n","  )\n","  (contract4): ContractingBlock(\n","    (contracting_layer1): Sequential(\n","      (0): Conv2d(32, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","    )\n","  )\n","  (contract5): ContractingBlock(\n","    (contracting_layer1): Sequential(\n","      (0): Conv2d(64, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (3): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (9): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2), padding_mode=reflect)\n","    )\n","  )\n","  (contract6): ContractingBlock(\n","    (contracting_layer1): Sequential(\n","      (0): Conv2d(128, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (3): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","    )\n","  )\n","  (contract7): ContractingBlock(\n","    (contracting_layer1): Sequential(\n","      (0): Conv2d(256, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): LeakyReLU(negative_slope=0.2, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (9): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 2), padding_mode=reflect)\n","    )\n","  )\n","  (res0): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res1): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res2): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res3): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res4): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res5): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res6): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res7): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res8): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (1): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(512, 512, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), padding_mode=reflect)\n","      (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (expand1): ExpandingBlock(\n","    (expanding_layer1): Sequential(\n","      (0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (expanding_layer2): Sequential(\n","      (0): Conv2d(512, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): CELU(alpha=1.0, inplace=True)\n","      (3): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): CELU(alpha=1.0, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","    )\n","  )\n","  (expand2): ExpandingBlock(\n","    (expanding_layer1): Sequential(\n","      (0): Conv2d(256, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","    )\n","    (expanding_layer2): Sequential(\n","      (0): Conv2d(256, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): CELU(alpha=1.0, inplace=True)\n","      (3): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): CELU(alpha=1.0, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","    )\n","  )\n","  (expand3): ExpandingBlock(\n","    (expanding_layer1): Sequential(\n","      (0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (expanding_layer2): Sequential(\n","      (0): Conv2d(128, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): CELU(alpha=1.0, inplace=True)\n","      (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): CELU(alpha=1.0, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","    )\n","  )\n","  (expand4): ExpandingBlock(\n","    (expanding_layer1): Sequential(\n","      (0): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","    )\n","    (expanding_layer2): Sequential(\n","      (0): Conv2d(64, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): CELU(alpha=1.0, inplace=True)\n","      (3): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): CELU(alpha=1.0, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","    )\n","  )\n","  (expand5): ExpandingBlock(\n","    (expanding_layer1): Sequential(\n","      (0): ConvTranspose2d(32, 16, kernel_size=(2, 2), stride=(2, 2))\n","    )\n","    (expanding_layer2): Sequential(\n","      (0): Conv2d(32, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): CELU(alpha=1.0, inplace=True)\n","      (3): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): CELU(alpha=1.0, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(16, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","    )\n","  )\n","  (expand6): ExpandingBlock(\n","    (expanding_layer1): Sequential(\n","      (0): Conv2d(16, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","    )\n","    (expanding_layer2): Sequential(\n","      (0): Conv2d(16, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): CELU(alpha=1.0, inplace=True)\n","      (3): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): CELU(alpha=1.0, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(8, 8, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(8, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","    )\n","  )\n","  (expand7): ExpandingBlock(\n","    (expanding_layer1): Sequential(\n","      (0): Conv2d(8, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","    )\n","    (expanding_layer2): Sequential(\n","      (0): Conv2d(8, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (1): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): CELU(alpha=1.0, inplace=True)\n","      (3): Conv2d(4, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","      (4): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (5): CELU(alpha=1.0, inplace=True)\n","      (6): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(4, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(4, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (7): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(4, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(4, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","      (8): ResidualBlock(\n","        (residual_layer1): Sequential(\n","          (0): Conv2d(4, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (1): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","          (2): ReLU(inplace=True)\n","          (3): Conv2d(4, 4, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), padding_mode=reflect)\n","          (4): InstanceNorm2d(4, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","        )\n","      )\n","    )\n","  )\n","  (downfeature): FeatureMapBlock(\n","    (conv0): Conv2d(4, 3, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","  )\n","  (res_end1): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(3, 3, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","      (1): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(3, 3, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","      (4): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res_end2): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(3, 3, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","      (1): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(3, 3, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","      (4): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res_end3): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(3, 3, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","      (1): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(3, 3, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","      (4): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res_end4): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(3, 3, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","      (1): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(3, 3, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","      (4): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (res_end5): ResidualBlock(\n","    (residual_layer1): Sequential(\n","      (0): Conv2d(3, 3, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","      (1): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(3, 3, kernel_size=(13, 13), stride=(1, 1), padding=(6, 6), padding_mode=reflect)\n","      (4): InstanceNorm2d(3, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n","    )\n","  )\n","  (soft_sign): Softsign()\n",")"]},"metadata":{},"execution_count":71}],"source":["u_net.apply(initialize_weights)\n","# # Move both the encoder and the decoder to the selected device\n","u_net.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":130,"status":"ok","timestamp":1666712825419,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"},"user_tz":-210},"id":"5FJyvTCpeEEe","outputId":"bea2f8d2-91f1-421a-94dc-92ce6bbd8713"},"outputs":[{"output_type":"stream","name":"stdout","text":["===================================================\n","Number of Parameters:==>  552614515\n","===================================================\n"]}],"source":["pytorch_total_params = sum(p.numel() for p in u_net.parameters())\n","print(\"===================================================\")\n","print(\"Number of Parameters:==> \", pytorch_total_params)\n","print(\"===================================================\")\n"]},{"cell_type":"markdown","metadata":{"id":"wWaVY_lUM6_4"},"source":["# **Loss & Optimizer:**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1054,"status":"ok","timestamp":1666712826403,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"},"user_tz":-210},"id":"fBKGiUTLbjm2","outputId":"61ed5173-a6bb-4b0b-e59d-26352a05b4dc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Selected device:=> cuda\n"]}],"source":["### Define the loss function\n","res_loss_fn_mse = torch.nn.MSELoss()\n","\n","res_loss_fn_mae = torch.nn.L1Loss()\n","\n","lambda_recon = 1\n","\n","### Define an optimizer (both for the encoder and the decoder!)\n","\n","params_to_optimize = [\n","    # {'params': encoder.parameters()},\n","    {'params': u_net.parameters()}\n","]\n","\n","print(f'Selected device:=> {device}')\n","\n","unet_optimizer = torch.optim.Adam(u_net.parameters(), lr=lr)\n","# unet_optimizer = torch.optim.SGD(u_net.parameters(), lr=lr, momentum=0.9, weight_decay=0, dampening=0)\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(unet_optimizer, mode='min', factor=0.1, patience=3, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08, verbose=True) #.MultiStepLR(unet_optimizer, milestones=[30,80,130, 200], gamma=0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8iqcCbDfBwb5"},"outputs":[],"source":["# get_model_loss\n","def get_model_loss(reconstruct, raw, recon_criterion=res_loss_fn_mae, lambda_recon=lambda_recon):\n","    '''\n","    Return the loss of the generator given inputs.\n","    Parameters:\n","        gen: the generator; takes the condition and returns potential images\n","        disc: the discriminator; takes images and the condition and\n","          returns real/fake prediction matrices\n","        real: the real images (e.g. maps) to be used to evaluate the reconstruction\n","        \n","        recon_criterion: the reconstruction loss function; takes the generator \n","                    outputs and the real images and returns a reconstructuion \n","                    loss (which you aim to minimize)\n","        lambda_recon: the degree to which the reconstruction loss should be weighted in the sum\n","    '''\n","    # Steps: 1) Generate the fake images, based on the conditions.\n","    #        2) Evaluate the fake images and the condition with the discriminator.\n","    #        3) Calculate the adversarial and reconstruction losses.\n","    #        4) Add the two losses, weighting the reconstruction loss appropriately.\n","    model_rec_loss = recon_criterion(reconstruct, raw)\n","    model_loss = lambda_recon * model_rec_loss\n","    return model_loss"]},{"cell_type":"markdown","metadata":{"id":"g4shH3zTOaE5"},"source":["> # ðŸ”¶ **Train Function:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IxSr_01BOgIp"},"outputs":[],"source":["class AverageMeter(object):\n","  \"\"\"Computes and stores the average and current value\"\"\"\n","  def __init__(self):\n","    self.reset()\n","\n","  def reset(self):\n","    self.val = 0\n","    self.avg = 0\n","    self.sum = 0\n","    self.count = 0\n","  \n","  def update(self, val, n=1):\n","    self.val = val\n","    self.sum += val * n\n","    self.count += n\n","    self.avg = self.sum / self.count\n","\n","\n","### Training function\n","def train_epoch_den(epoch=0):\n","    # Set train mode for both the encoder and the decoder\n","    u_net.train()\n","\n","    loss_total = AverageMeter()\n","    # Iterate the dataloader (we do not need the label values, this is unsupervised learning)\n","    for iter, (noisy_batch, raw_batch) in enumerate(tqdm(train_loader)): # with \"_\" we just ignore the labels (the second element of the dataloader tuple)\n","        # Move tensor to the proper device\n","        noisy_batch = noisy_batch.to(device)\n","        raw_batch = raw_batch #.to(device)\n","        unet_optimizer.zero_grad()\n","        # U-Net data\n","        decoded_data = u_net(noisy_batch)\n","\n","        # Evaluate loss\n","        # res_loss_mse = res_loss_fn_mse((raw_batch - noisy_batch), decoded_data)\n","        # res_loss = res_loss_fn_mae((decoded_data + noisy_batch), raw_batch.cuda())\n","        res_loss = get_model_loss((decoded_data + noisy_batch), raw_batch.cuda(), recon_criterion=res_loss_fn_mae, lambda_recon=lambda_recon)\n","        # res_loss = res_loss_mae\n","        # Backward pass\n","        res_loss.backward()\n","        unet_optimizer.step()\n","        # Print batch loss\n","        # print('\\t partial train loss (single batch): %f' % (loss.data))\n","        loss_total.update(res_loss)\n","        writer.add_scalar('Iteration_Loss/train', loss_total.avg.item(), epoch * len(train_loader) + iter)\n","\n","    writer.add_scalar('Epoch_Loss/train', loss_total.avg.item(), epoch)\n","\n","    return loss_total.avg.item() # np.mean(res_train_loss)\n","\n","\n","### Testing function\n","def test_epoch_den(epoch):\n","    # Set evaluation mode for encoder and decoder\n","    u_net.eval()\n","    loss_total = AverageMeter()\n","\n","    with torch.no_grad(): # No need to track the gradients\n","        # Define the lists to store the outputs for each batch\n","        # with tqdm(test_loader, unit=\"batch\") as tepoch:\n","        for iter, (noisy_batch, raw_batch) in enumerate(tqdm(test_loader)): #zip(tqdm(test_decoded_loader), test_raw_loader):\n","            # Move tensor to the proper device\n","            noisy_batch = noisy_batch.to(device)\n","            raw_batch = raw_batch #.to(device)\n","            # Encode data\n","            decoded_data = u_net(noisy_batch)\n","            # Append the network output and the original image to the lists\n","            # res_loss_mse = res_loss_fn_mse((raw_batch - noisy_batch), decoded_data)\n","            # res_loss = res_loss_fn_mae((decoded_data + noisy_batch), raw_batch.cuda())\n","            res_loss = get_model_loss((decoded_data + noisy_batch), raw_batch.cuda(), recon_criterion=res_loss_fn_mae, lambda_recon=lambda_recon)\n","            # res_loss = res_loss_mae\n","            loss_total.update(res_loss)\n","            writer.add_scalar('Iteration_Loss/test', loss_total.avg.item(), epoch * len(test_loader) + iter)\n","\n","    writer.add_scalar('Epoch_Loss/test', loss_total.avg.item(), epoch)\n","\n","    return loss_total.avg.item()\n","\n","# train_epoch_den()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n7lGKMHNzEhc"},"outputs":[],"source":["# torch.cuda.memory_summary(device=None, abbreviated=False)\n","# torch.cuda.empty_cache()\n","\n","def plot_ae_outputs_den(my_model, my_loader, device, n=1):\n","    plt.figure(figsize=(12, 30))\n","    my_model.eval()\n","    for i in range(n):\n","        ax = plt.subplot(6, n, i+1)\n","        image_noisy, org_img = next(iter(my_loader)) #test_raw_dataset[i][0].unsqueeze(0)\n","        org_img = org_img[i].to(device)\n","        image_noisy = image_noisy[i].to(device)\n","        with torch.no_grad():\n","            image_noisy = image_noisy.to(device)\n","            residual_img = my_model(image_noisy.view(1, 3, 240, 320))\n","\n","        # new_data = ndimage.rotate(img.cpu().squeeze().numpy().T, angle, reshape=True)\n","        # ax.imshow((org_img.detach().permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8));\n","        ax.imshow(normalize_image(org_img).detach().permute(1, 2, 0).cpu().numpy());\n","      \n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False)\n","        ax.get_yaxis().set_visible(False)\n","        if i == n//2:\n","            ax.set_title('Original image', color=\"red\", fontweight=\"bold\")\n","        ax = plt.subplot(6, n, i + 1 + n);\n","        # new_data = ndimage.rotate(image_noisy.cpu().squeeze().numpy().T, angle, reshape=True)\n","        # ax.imshow((image_noisy.detach().permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8))\n","        ax.imshow(normalize_image(image_noisy).permute(1, 2, 0).cpu().numpy());\n","        # plt.imshow(image_noisy.cpu().reshape(256, 512, 3))\n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False)\n","        ax.get_yaxis().set_visible(False)\n","        if i == n//2:\n","            ax.set_title('Corrupted image', color=\"red\", fontweight=\"bold\")\n","        # print(torch.max((org_img - image_noisy)))\n","        # print(\"Calc Res:=> \", torch.max(residual_img))\n","        ax = plt.subplot(6, n, i + 1 + n + n);\n","        # new_data = ndimage.rotate(rec_img.cpu().squeeze().numpy().T, angle, reshape=True)\n","        # plt.imshow(rec_img.cpu().reshape(360, 640, 3))\n","        # print(residual_img.size())\n","        reconstructed_img = image_noisy.cpu() + residual_img.cpu()\n","\n","        # ax.imshow((reconstructed_img.view(3, 360, 640).permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8));\n","        ax.imshow(normalize_image(reconstructed_img.view(3, 240, 320)).permute(1, 2, 0).cpu().numpy());\n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False);\n","        ax.get_yaxis().set_visible(False); \n","        if i == n//2:\n","            ax.set_title('Reconstructed image', color=\"red\", fontweight=\"bold\")\n","        \n","        ax = plt.subplot(6, n, i + 1 + n + n + n);\n","\n","        # ax.imshow((residual_img.detach().view(3, 360, 640).permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8));\n","        ax.imshow(normalize_image(residual_img.view(3, 240, 320)).permute(1, 2, 0).cpu().numpy());\n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False);\n","        ax.get_yaxis().set_visible(False); \n","        if i == n//2:\n","            ax.set_title('Model Residual image', color=\"red\", fontweight=\"bold\")\n","        \n","        ax = plt.subplot(6, n, i + 1 + n + n + n + n);\n","\n","        # ax.imshow((torch.abs(org_img - image_noisy).detach().view(3, 360, 640).permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8));\n","        ax.imshow(normalize_image((org_img - image_noisy).view(3, 240, 320)).permute(1, 2, 0).cpu().numpy());\n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False);\n","        ax.get_yaxis().set_visible(False); \n","        if i == n//2:\n","            ax.set_title('Real Residual image', color=\"red\", fontweight=\"bold\")\n","\n","        ax = plt.subplot(6, n, i + 1 + n + n + n + n + n);\n","\n","        # ax.imshow((torch.abs(org_img - image_noisy).detach().view(3, 360, 640).permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8));\n","        ax.imshow(normalize_image(((org_img - image_noisy) - residual_img).view(3, 240, 320)).permute(1, 2, 0).cpu().numpy());\n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False);\n","        ax.get_yaxis().set_visible(False); \n","        if i == n//2:\n","            ax.set_title('Diff Residual image', color=\"red\", fontweight=\"bold\")\n","    \n","    plt.subplots_adjust(left=0.0,\n","                        bottom=0.001, \n","                        right=0.9, \n","                        top=0.999, \n","                        wspace=0., \n","                        hspace=0.1,\n","                        );\n","    plt.show();\n","\n","# plot_ae_outputs_den(my_model=u_net, my_loader=test_loader2, device=device);"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BlzVOgZPRGEp"},"outputs":[],"source":["# import logging\n","# import pytz #import timezone\n","# from datetime import datetime\n","# logging.basicConfig(format='%(asctime)s --- %(levelname)s: %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', level=logging.DEBUG)\n","# logger = logging.getLogger('My_Logger')\n","# # logger.setLevel(logging.DEBUG)\n","# tz = pytz.timezone('Asia/Tehran')\n","# def timetz(*args):\n","#     return datetime.now(tz).timetuple()\n","\n","# logging.Formatter.converter = timetz\n","# logger.info('This is an info message')"]},{"cell_type":"markdown","metadata":{"id":"Q3Qo0TJueGfw"},"source":["> # ðŸ”¶ **CheckPointing:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6J2EBuwNcw-"},"outputs":[],"source":["class Checkpoint(object):\n","    def __init__(self, model_name='', checkpoint_path_model=''):\n","        # self.best_acc = 0.0\n","        self.folder = 'checkpoint'\n","        self.model_name = model_name\n","        self.checkpoint_path = str(checkpoint_path_model)\n","        os.makedirs(self.folder, exist_ok=True)\n","\n","    def save(self, model='', epoch=-1, res_train_loss=0, res_val_loss=0, train_loss=0, val_loss=0):\n","        # if acc > self.best_acc:\n","        print('Saving checkpoint...')\n","        state = {\n","            'net': model.state_dict(),\n","            'res_train_loss': res_train_loss,\n","            'res_val_loss': res_val_loss,\n","            'train_loss': train_loss,\n","            'val_loss': val_loss,\n","            'epoch': epoch,\n","            'learning_rate': lr,\n","        }\n","        path = os.path.join(os.path.abspath(self.folder), self.model_name + '_' + str(epoch) +'.pth')\n","        torch.save(state, path)\n","        \n","        str_path = str(path)\n","        # print(str_path)\n","        !cp -av \"$str_path\" \"$self.checkpoint_path\"\n","        # self.best_acc = acc\n","        !rm -rf \"$str_path\"\n","\n","\n","    def load(self, model='', epoch=-1):\n","        drive_PATH = os.path.join(self.checkpoint_path, self.model_name + '_' + str(epoch) +'.pth')\n","        str_drive_PATH = str(drive_PATH)\n","        str_abs_PATH = str(os.path.abspath(self.folder))\n","        print(str_drive_PATH)\n","        print(str_abs_PATH)\n","        !cp -av \"$str_drive_PATH\" '/content/checkpoint'\n","\n","        PATH = os.path.join(os.path.abspath(self.folder), self.model_name + '_' + str(epoch) +'.pth')\n","        str_path = str(PATH)\n","        \n","        checkpoint = torch.load(PATH)\n","        model.load_state_dict(checkpoint['net'])\n","        # model.eval()\n","        pass\n","my_unet_checkpoint = Checkpoint(model_name='checkpoint_unet', checkpoint_path_model=checkpoint_path_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8SwiTDWuZA8V"},"outputs":[],"source":["class LossHistory(object):\n","    def __init__(self, model_name='U_Net', checkpoint_path_loss=''):\n","        self.folder = 'Loss_History'\n","        self.model_name = model_name\n","        os.makedirs(self.folder, exist_ok=True)\n","        self.checkpoint_path = str(checkpoint_path_loss)\n","        self.file_name = None\n","        self.file_path = None\n","\n","    def save(self, loss_history={}, start_epoch=0, num_epochs=100, epoch=-1):\n","        history_track = {}  # loss history\n","        history_track['train_loss'] = loss_history['train_loss']\n","        history_track['valid_loss'] = loss_history['valid_loss']\n","        history_track['res_train_loss'] = loss_history['res_train_loss']\n","        history_track['res_valid_loss'] = loss_history['res_valid_loss']\n","        history_track['start_epoch'] = start_epoch\n","        history_track['num_epochs'] = num_epochs\n","        history_track['epoch'] = epoch\n","        self.file_name = self.model_name + '_' + 'Loss' + '_' + str(epoch) + '.json'\n","        jason_file = open(os.path.join(os.path.abspath(self.folder), self.file_name), \"w\")\n","        json.dump(history_track, jason_file)\n","        jason_file.close()\n","\n","        self.file_path = os.path.join(os.path.abspath(self.folder), self.file_name)\n","        str_path = str(self.file_path)\n","        # print(str_path)\n","        !cp -av \"$str_path\" \"$self.checkpoint_path\"\n","        # self.best_acc = acc\n","        # !rm -rf \"$str_path\"\n","    \n","    def load(self, epoch=-1):\n","        self.file_name = self.model_name + '_' + 'Loss' + '_' + str(epoch) + '.json'\n","        drive_PATH = os.path.join(self.checkpoint_path, self.file_name)\n","        str_drive_PATH = str(drive_PATH)\n","        str_abs_PATH = str(os.path.abspath(self.folder))\n","\n","        # print(str_drive_PATH)\n","        # print(str_abs_PATH)\n","        !cp -av \"$str_drive_PATH\" \"$str_abs_PATH\"\n","\n","        with open(os.path.join(str_abs_PATH, str(self.file_name)), 'r') as json_file:\n","            json_data = json.load(json_file)\n","            print(\"\\nTrain Loos:=> \", json_data['res_train_loss'])\n","            print(\"\\nTest Loss:=> \", json_data['res_valid_loss'])\n","            print(\"\\nStart Epoch:=> \", json_data['start_epoch'])\n","            print(\"\\nEpoch:=> \", json_data['epoch'])\n","            loss_history = {'train_loss':json_data['train_loss'],\n","                            'valid_loss':json_data['valid_loss'],\n","                            'res_train_loss':json_data['res_train_loss'],\n","                            'res_valid_loss':json_data['res_valid_loss'],\n","                            }\n","            start_epoch = json_data['start_epoch']\n","            num_epochs = json_data['num_epochs']\n","            epoch = json_data['epoch']\n","        return loss_history, start_epoch, num_epochs, epoch    \n","\n","\n","unet_loss_hsitory = LossHistory(model_name='U_Net', checkpoint_path_loss=checkpoint_path_loss)\n","# unet_loss_hsitory.load(epoch=13)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5OrkytsYXDWB"},"outputs":[],"source":["start_epoch = 0\n","num_epochs = 101\n","epoch_ = 0\n","loss_history = {}\n","history_da={'train_loss':[],\n","            'valid_loss':[],\n","            'res_train_loss':[],\n","            'res_valid_loss':[],\n","            }\n","\n","if load_losses is True:\n","    loss_history, start_epoch, num_epochs, epoch_ = unet_loss_hsitory.load(epoch=load_epoch)\n","    print(loss_history)\n","    start_epoch = epoch_ + 1\n","\n","    print(\"Start Epoch:===> \", start_epoch)\n","    print(\"Num epochs:===> \", num_epochs)\n","    print(\"Epoch:===> \", epoch_)\n","    history_da['train_loss'] = loss_history['train_loss']\n","    history_da['valid_loss'] = loss_history['valid_loss']\n","    history_da['res_train_loss'] = loss_history['res_train_loss']\n","    history_da['res_valid_loss'] = loss_history['res_valid_loss']\n","    print(history_da)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"output_embedded_package_id":"1UbjfJkHAEQ_wO8SjC0tJRW2TN8P4VkYb","base_uri":"https://localhost:8080/","height":1000},"id":"kXkCh5tmvQBK","outputId":"d8ae5fc3-553a-4af3-f116-de358c060fd3","executionInfo":{"status":"ok","timestamp":1666706836621,"user_tz":-210,"elapsed":11790,"user":{"displayName":"Micro Artificial Intelligence","userId":"17845925503443629912"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["if load_model is True:\n","    my_unet_checkpoint.load(model=u_net, epoch=load_epoch)\n","\n","plot_ae_outputs_den(my_model=u_net, my_loader=test_loader, device=device);"]},{"cell_type":"markdown","metadata":{"id":"vYXRxk1W9Jrt"},"source":["> # ðŸ”¶ **Training Process:**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_JCvzGL91Imj"},"outputs":[],"source":["from torch.utils.tensorboard import SummaryWriter\n","\n","try:\n","  from google import colab\n","  COLAB_ENV = True\n","except (ImportError, ModuleNotFoundError):\n","  COLAB_ENV = False\n","if COLAB_ENV:\n","  %load_ext tensorboard\n","  %tensorboard --logdir runs\n","else:\n","  print(\"To use tensorboard, please use this notebook in a Google Colab environment!\")\n","\n","writer = SummaryWriter('runs/nature_video')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"referenced_widgets":["7e92f2668c9c4a79836976f426f6b5b1"]},"id":"4Z4McaIvOq4v","outputId":"cc0c343e-2f29-4198-e9f9-71843c4de1fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["EPOCH 32/133\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e92f2668c9c4a79836976f426f6b5b1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5175 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["### Training cycle\n","\n","for epoch in range(start_epoch, start_epoch + num_epochs):\n","    print('EPOCH %d/%d' % (epoch, start_epoch + num_epochs))\n","    ### Training (use the training function)\n","    res_train_loss = train_epoch_den(\n","        epoch=epoch\n","    )\n","    ### Validation  (use the testing function)\n","    res_val_loss = test_epoch_den(\n","        epoch=epoch\n","    )\n","    scheduler.step(res_val_loss)\n","    # Print Validationloss\n","    # history_da['train_loss'].append(float(train_loss))\n","    # history_da['valid_loss'].append(float(val_loss))\n","    history_da['res_train_loss'].append(float(res_train_loss))\n","    history_da['res_valid_loss'].append(float(res_val_loss))\n","    print('\\n EPOCH {}/{} \\t Residual train loss {:.8f} \\t Residual val loss {:.12f}'.format(epoch, num_epochs, res_train_loss, res_val_loss))\n","\n","    if (epoch % 2) == 0:\n","        plot_ae_outputs_den(my_model=u_net, my_loader=test_loader, device=device)\n","    my_unet_checkpoint.save(model=u_net, epoch=epoch, res_train_loss=res_train_loss, res_val_loss=res_val_loss, train_loss=0, val_loss=0)\n","    unet_loss_hsitory.save(loss_history=history_da, start_epoch=start_epoch, num_epochs=num_epochs, epoch=epoch)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Rm1agsVwYZf2"},"outputs":[],"source":["fig = plt.figure(figsize=(10, 7));\n","# plt.plot(history_da['res_train_loss'][0:24], label='Res-Train loss')\n","valid_losses = history_da['res_valid_loss'][:24]\n","train_losses = history_da['res_train_loss'][:24]\n","initialize_loss1 = 0.036506280303001404\n","initialize_loss2 = 0.036506280303001404\n","valid_losses.insert(0, initialize_loss1)\n","train_losses.insert(0, initialize_loss2)\n","plt.plot(train_losses, label='Res-Train loss')\n","plt.plot(valid_losses, label='Res-Validation loss')\n","plt.axhline(y=0.0, label='Zero Test Loss', c='red')\n","\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Residual Loss\")\n","plt.title(\"Calculated Res-Losses for ADE\", fontsize=15)\n","plt.legend();\n","plt.show();"]},{"cell_type":"markdown","metadata":{"id":"VwQXunoQLGWS"},"source":["# **Reconstructing Video:**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"66aQgv6CvsS5"},"outputs":[],"source":["fig = plt.figure(figsize=(10, 7));\n","plt.plot(np.log(history_da['res_train_loss']), label='Res-Train loss')\n","plt.plot(np.log(history_da['res_val_loss']), label='Res-Validation loss')\n","plt.axhline(y=np.log(0.00093651661882176995), label='Zero Test Loss')\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Residual Loss\")\n","plt.title(\"Calculated Log Res-Losses for ADE\", fontsize=15)\n","plt.legend();\n","plt.show();"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HW4uGh2gX8av"},"outputs":[],"source":["fig = plt.figure(figsize=(10, 7));\n","plt.plot(np.log(history_da['train_loss']), label='Train loss')\n","plt.plot(np.log(history_da['val_loss']), label='Validation loss')\n","plt.axhline(y=np.log(0.00093651661882176995), label='Zero Test Loss')\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"Residual Loss\")\n","plt.title(\"Calculated Log Losses for ADE\", fontsize=15)\n","plt.legend();\n","plt.show();"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"VUQ1bYhZv_9U"},"outputs":[],"source":["fig = plt.figure(figsize=(10, 7))\n","multiplied_list1 = [element * 1000000 for element in history_da['train_loss']]\n","multiplied_list2 = [element * 1000000 for element in history_da['val_loss']]\n","plt.plot(multiplied_list1, label='Train loss')\n","plt.plot(multiplied_list2, label='Validation loss')\n","plt.xlabel(\"Iteration\")\n","plt.ylabel(\"10^6 x Loss\")\n","plt.title(\"Calculated 10^6xLosses for ADE\", fontsize=15)\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"L3jMUKtgOs_Q"},"outputs":[],"source":["# img_noise = iter(noise_dataloader).next()\n","# img = iter(dataloader_train).next()\n","\n","\n","# # import matplotlib.pyplot as plt\n","# # a = np.array([1,2,3,4,5])\n","# # a = np.expand_dims(a, axis=0)  # or axis=1\n","# # plt.imshow(a)\n","# # plt.show()\n","# # with torch.no_grad():\n","# #     rec_img_noise  = decoder(encoder(img_noise[0]))\n","\n","\n","\n","# import numpy as np\n","\n","# def valid_imshow_data(data):\n","#     data = np.asarray(data)\n","#     if data.ndim == 2:\n","#         return True\n","#     elif data.ndim == 3:\n","#         if 3 <= data.shape[2] <= 4:\n","#             return True\n","#         else:\n","#             print('The \"data\" has 3 dimensions but the last dimension '\n","#                   'must have a length of 3 (RGB) or 4 (RGBA), not \"{}\".'\n","#                   ''.format(data.shape[2]))\n","#             return False\n","#     else:\n","#         print('To visualize an image the data must be 2 dimensional or '\n","#               '3 dimensional, not \"{}\".'\n","#               ''.format(data.ndim))\n","#         return False\n","\n","# print(img_noise[0][0].shape)\n","# a = valid_imshow_data(img_noise[0][0])\n","\n","\n","# #     rec_img  = img[0]))\n","# plt.imshow(torch.squeeze(img_noise[0][0]).reshape(288, 352, 3))\n","# # rec_img_noise(img[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"OK_lrrBb9sar"},"outputs":[],"source":["my_loss = nn.MSELoss()\n","\n","no_dae_loss = []\n","for (noise_batch, _), (image_batch, _) in zip(train_decoded_loader, train_raw_loader):\n","    # Move tensor to the proper device\n","    # image_noisy = add_noise(image_batch,noise_factor)\n","    # image_noisy = noise_batch.to(device)\n","    # Encode data\n","    # encoded_data = encoder(image_noisy)\n","    # Decode data\n","    # decoded_data = decoder(encoded_data)\n","    # Append the network output and the original image to the lists\n","    # conc_out.append(decoded_data.cpu())\n","    # conc_label.append(image_batch.cpu())\n","    loss = my_loss(noise_batch.cpu(), image_batch.cpu())\n","    no_dae_loss.append(loss.detach().cpu().numpy())\n","\n","print(\"Train Loss without DAE:=> \", np.mean(no_dae_loss))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"AfPswEvyaoWN"},"outputs":[],"source":["my_loss = nn.MSELoss()\n","\n","no_dae_loss = []\n","for (noise_batch, _), (image_batch, _) in zip(test_decoded_loader, test_raw_loader):\n","    # Move tensor to the proper device\n","    # image_noisy = add_noise(image_batch,noise_factor)\n","    # image_noisy = noise_batch.to(device)\n","    # Encode data\n","    # encoded_data = encoder(image_noisy)\n","    # Decode data\n","    # decoded_data = decoder(encoded_data)\n","    # Append the network output and the original image to the lists\n","    # conc_out.append(decoded_data.cpu())\n","    # conc_label.append(image_batch.cpu())\n","    loss = my_loss(noise_batch.cpu(), image_batch.cpu())\n","    no_dae_loss.append(loss.detach().cpu().numpy())\n","\n","print(\"Test Loss without DAE:=> {:.12f}\".format(np.mean(no_dae_loss)))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6Sa28KxIG3gO"},"outputs":[],"source":["batch1_decoded, batch_raw = next(iter(train_loader))\n","\n","plt.imshow(batch1_decoded[7].view(3, 256, 512).permute(1, 2, 0).detach().cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Q6jQw4-FOFTe"},"outputs":[],"source":["\n","plt.imshow(batch1_decoded[7].view(3, 256, 512).permute(1, 2, 0).detach().cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Ro4h9cXdLIcu"},"outputs":[],"source":["torch.cuda.empty_cache()\n","del encoded_data\n","del decoded_data\n","del test_loader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6c563mP3J5t2"},"outputs":[],"source":["encoded_data = u_net(batch1_decoded[7].view(1, 3, 256, 512).to(device))\n","# Decode data\n","# decoded_data = decoder(encoded_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"YahoSARE6ke6"},"outputs":[],"source":["print(decoded_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"dioqsIKYKdny"},"outputs":[],"source":["reconstructed_img = batch1_decoded[7].detach().cpu() + decoded_data.detach().cpu()\n","plt.imshow(reconstructed_img.view(3, 256, 512).permute(1, 2, 0).numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JeK6kxkL8rLR"},"outputs":[],"source":["from torchvision.utils import save_image\n","save_image(batch1_decoded[7], \"noisy.bmp\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"x0VEs64J9S7R"},"outputs":[],"source":["save_image(reconstructed_img, \"reconstructed_img.bmp\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"RicTCCl49ZL6"},"outputs":[],"source":["\n","save_image(batch_raw[7], \"raw_img.bmp\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"-QpZdJt1Kmfw"},"outputs":[],"source":["import cv2\n","# img       = 255 - cv2.resize(batch1_decoded[7],       (0,0), fx = 1/scale_w, fy = 1/scale_h)\n","# cv2.imwrite(os.path.join('/content', 'img', 'noisy', '{}.jpg'.format(str(1).zfill(6))), img)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"7qU45AGapQvC"},"outputs":[],"source":["class ImageFolderNew(ImageFolder):\n","    def _find_classes(self, dir):\n","        \"\"\"\n","        Finds the class folders in a dataset.\n","\n","        Args:\n","            dir (string): Root directory path.\n","\n","        Returns:\n","            tuple: (classes, class_to_idx) where classes are relative to (dir), and class_to_idx is a dictionary.\n","\n","        Ensures:\n","            No class is a subdirectory of another.\n","        \"\"\"\n","        if sys.version_info >= (3, 5):\n","            # Faster and available in Python 3.5 and above\n","            classes = [d.name for d in os.scandir(dir) if d.is_dir()]\n","        else:\n","            classes = [d for d in os.listdir(dir) if os.path.isdir(os.path.join(dir, d))]\n","        classes.sort(key=int)\n","        class_to_idx = {classes[i]: i for i in range(len(classes))}\n","        return classes, class_to_idx\n","\n","\n","class MyDataset(Dataset):\n","    def __init__(self, datasetA_dir, datasetB_dir, transform=None):\n","        self.datasetA_dir = datasetA_dir\n","        self.datasetB_dir = datasetB_dir\n","        self.transform = transform\n","        \n","    def __getitem__(self, index):\n","        # print(\"index: \", index)\n","        # print(\"dirA: \", self.datasetA_dir)\n","        # print(\"dirB: \", self.datasetB_dir)\n","        # print(\"LenA: \", len(self.datasetA_dir))\n","        # print(\"LenB: \", len(self.datasetB_dir))\n","        digA = \"compframe00315\"  + \".png\"\n","        dirA = os.path.join(self.datasetA_dir, digA)\n","        digB = \"rawframe00315\" + \".png\"\n","        dirB = os.path.join(self.datasetB_dir, digB)\n","        # xA = self.datasetA_dir[index]\n","        # xB = self.datasetB_dir[index]\n","        imageA = io.imread(dirA)\n","        imageB = io.imread(dirB)\n","        if self.transform:\n","            imageA = self.transform(imageA)\n","            imageB = self.transform(imageB)\n","        return imageA, imageB\n","    \n","    def __len__(self):\n","        path, dirs, filesA = next(os.walk(self.datasetA_dir))\n","        # path, dirs, filesB = next(os.walk(self.datasetB_dir))\n","        file_countA = len(filesA)\n","        # file_countB = len(filesB)\n","        # print(\"File CountA: \", file_countA)\n","        # print(\"File CountB: \", file_countB)\n","        # print(\"Len Decoded:\", len(self.datasetA_dir))\n","        # print(\"Len Raw:\", len(self.datasetB_dir))\n","        return file_countA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"DLd1l_Tlmrio"},"outputs":[],"source":["test_dataset2 = MyDataset('/content/Frame2/dec/', '/content/Frame2/raw/', transform=transforms.Compose([\n","                                transforms.ToTensor(),\n","                                torchvision.transforms.Normalize(\n","                                  mean=[0.5, 0.5, 0.5],\n","                                  std=[0.5, 0.5, 0.5],\n","                              ),\n","                            ])\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Ag-zv-VOOmwP"},"outputs":[],"source":["test_loader2 = torch.utils.data.DataLoader(test_dataset2, batch_size=1, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"eo_fQjSynWfH"},"outputs":[],"source":["image_noisy, org_img = next(iter(test_loader2))\n","\n","image_noisy = image_noisy.to(device)\n","residual_img = u_net(image_noisy.view(1, 3, 360, 640))\n","\n","# res = u_net(test_loader2)\n","\n","reconstructed_img = image_noisy.detach().cpu() + residual_img.detach().cpu()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"JAEP8AIdpotm"},"outputs":[],"source":["from torchvision.utils import save_image\n","save_image(normalize_image(reconstructed_img.view(3, 360, 640)), \"res2.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"NoHlTGhln0fa"},"outputs":[],"source":["def plot_ae_outputs_den(my_model, my_loader, device, n=1, size=(3, 360, 640)):\n","    plt.figure(figsize=(25, 37))\n","    my_model.eval()\n","    for i in range(n):\n","        ax = plt.subplot(6, n, i+1)\n","        image_noisy, org_img = next(iter(my_loader)) #test_raw_dataset[i][0].unsqueeze(0)\n","        org_img = org_img[i].to(device)\n","        image_noisy = image_noisy[i].to(device)\n","        with torch.no_grad():\n","            image_noisy = image_noisy.to(device)\n","            residual_img = my_model(image_noisy.view(1, 3, 360, 640))\n","\n","        # new_data = ndimage.rotate(img.cpu().squeeze().numpy().T, angle, reshape=True)\n","        # ax.imshow((org_img.detach().permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8));\n","        ax.imshow(normalize_image(org_img).detach().cpu().permute(1, 2, 0).numpy());\n","      \n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False)\n","        ax.get_yaxis().set_visible(False)  \n","        if i == n//2:\n","            ax.set_title('Original image')\n","        ax = plt.subplot(6, n, i + 1 + n);\n","        # new_data = ndimage.rotate(image_noisy.cpu().squeeze().numpy().T, angle, reshape=True)\n","        # ax.imshow((image_noisy.detach().permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8))\n","        ax.imshow(normalize_image(image_noisy).detach().cpu().permute(1, 2, 0).numpy());\n","        # plt.imshow(image_noisy.cpu().reshape(256, 512, 3))\n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False)\n","        ax.get_yaxis().set_visible(False)  \n","        if i == n//2:\n","            ax.set_title('Corrupted image')\n","        # print(torch.max((org_img - image_noisy)))\n","        # print(\"Calc Res:=> \", torch.max(residual_img))\n","        ax = plt.subplot(6, n, i + 1 + n + n);\n","        # new_data = ndimage.rotate(rec_img.cpu().squeeze().numpy().T, angle, reshape=True)\n","        # plt.imshow(rec_img.cpu().reshape(360, 640, 3))\n","        # print(residual_img.size())\n","        reconstructed_img = image_noisy.detach().cpu() + residual_img.detach().cpu()\n","\n","        # ax.imshow((reconstructed_img.view(3, 360, 640).permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8));\n","        ax.imshow(normalize_image(reconstructed_img.view(3, 360, 640)).detach().cpu().permute(1, 2, 0).numpy());\n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False);\n","        ax.get_yaxis().set_visible(False); \n","        if i == n//2:\n","            ax.set_title('Reconstructed image')\n","        \n","        ax = plt.subplot(6, n, i + 1 + n + n + n);\n","\n","        # ax.imshow((residual_img.detach().view(3, 360, 640).permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8));\n","        ax.imshow((residual_img.view(3, 360, 640) * 255).detach().cpu().permute(1, 2, 0).numpy().astype('uint8'), vmin=0, vmax=255);\n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False);\n","        ax.get_yaxis().set_visible(False); \n","        if i == n//2:\n","            ax.set_title('Model Residual image')\n","        \n","        ax = plt.subplot(6, n, i + 1 + n + n + n + n);\n","\n","        # ax.imshow((torch.abs(org_img - image_noisy).detach().view(3, 360, 640).permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8));\n","        ax.imshow((torch.abs(org_img - image_noisy).view(3, 360, 640) * 255).detach().permute(1, 2, 0).cpu().numpy().astype('uint8'), vmin=0, vmax=255);\n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False);\n","        ax.get_yaxis().set_visible(False); \n","        if i == n//2:\n","            ax.set_title('Real Residual image')\n","\n","        ax = plt.subplot(6, n, i + 1 + n + n + n + n + n);\n","\n","        # ax.imshow((torch.abs(org_img - image_noisy).detach().view(3, 360, 640).permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8));\n","        ax.imshow((torch.abs(torch.abs(org_img - image_noisy) - residual_img).view(3, 360, 640) * 255).detach().permute(1, 2, 0).cpu().numpy().astype('uint8'), vmin=0, vmax=255);\n","        # tr = transforms.Affine2D().rotate_deg(180)\n","        # ax.imshow(img.cpu().squeeze().numpy().T, transform=tr + ax.transData)\n","        ax.get_xaxis().set_visible(False);\n","        ax.get_yaxis().set_visible(False); \n","        if i == n//2:\n","            ax.set_title('Diff Residual image')\n","    \n","    plt.subplots_adjust(left=0.0,\n","                        bottom=0.001, \n","                        right=0.9, \n","                        top=0.999, \n","                        wspace=0., \n","                        hspace=0.1,\n","                        );\n","    plt.show();"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["_ebAc19vIMRb","BgJcAODtJva3","r3qmP0qBMzjo","wWaVY_lUM6_4","g4shH3zTOaE5","Q3Qo0TJueGfw","VwQXunoQLGWS"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}